,Posts,clean_posts,len,Sentiment
0,"['For a recent meetup I wanted to query the website ', ""Unfortunately Power BI isn't compatible with the API this provider uses.  They use a 308 Permanent redirect as the initial response, requiring an additional request. After a bit of digging Power Query only handles redirects up to 307.  I have a suspicion this is .net problem, hence, may not be within control of the Power BI team to sort out."", 'I used this blockage to test out using a Python script as a data source for Power BI.', 'The Python web client has no problem handling 308 redirects, thankfully.', ""I'm running Python under a Conda environment so I had to set the options in Power BI to look at this environment path."", 'I then created Python code and tested it with VS Code.  Note, to get the script working with Power BI you need to install packages for pandas and matplotlib.', 'Power Query is not very good at processing JSON,hence, I cleaned the data in Python and constructed the Data Frame with individual lists so I could take care of missing elements.   ', 'Once your happy with the data, open Power BI and Get Data from Python Script.', 'Paste in the Python Script.', 'Power BI will then execute the script returning data like any other data, giving you the option to Load or Transform.', 'I did a little data cleaning in Power Query as there is some data held in nested lists.', 'In summary, you have a quite a bit of Power to extend the Get Data source without having to learn about the Custom Connector route. I hope Microsoft handle 308 responses soon as I only had to write this code due to the non-conformance of the ', ""If any MVP's pick this bug up I would appreciate you feeding back to Microsoft as I expect more and more providers to use 308 redirects for future proofing."", '© 2019 Lee Hawthorn']",recent meetup want queri websit unfortun power bi compat api provid use use perman redirect initi respons requir addit request bit dig power queri handl redirect suspicion net problem henc may within control power bi team sort use blockag test use python script data sourc power bi python web client problem handl redirect thank run python conda environ set option power bi look environ path creat python code test vs code note get script work power bi need instal packag panda matplotlib power queri good process json henc clean data python construct data frame individu list could take care miss element happi data open power bi get data python script past python script power bi execut script return data like data give option load transform littl data clean power queri data held nest list summari quit bit power extend get data sourc without learn custom connector rout hope microsoft handl respons soon write code due non conform mvp pick bug would appreci feed back microsoft expect provid use redirect futur proof lee hawthorn,1034,1
1,"['This is a post for demonstrating NLTK for Sentiment Analysis ', 'Save me, from this way', 'It be, killing me', 'Yeah I been sitting here dreaming,', 'Yea one day, of being free', 'Save me, save me, save me, oh save me.', 'Save me, from this girl', 'She be, killing me', 'I been sitting here dreaming', 'Yea one day, of being free', 'Save me, save me, who gonna save me? Yea save me.', 'Save me, from this song', 'It be boring me', 'I been sitting here dreaming', 'Yea one day, of being free', 'Save me, save me, who gonna save me, save me yea, save me', 'who gonna save me, baby hang on, save me, hang on, save me', 'yea gonna save me, who gonna save me', 'yea but who gonna save me, oh who gonna save me...diddly-bo', 'very bad negative song terrible and sad', '© 2019 Lee Hawthorn']",post demonstr nltk sentiment analysi save way kill yeah sit dream yea one day free save save save oh save save girl kill sit dream yea one day free save save gonna save yea save save song bore sit dream yea one day free save save gonna save save yea save gonna save babi hang save hang save yea gonna save gonna save yea gonna save oh gonna save diddli bo bad neg song terribl sad lee hawthorn,393,1
2,"['In this post I give an example of making a prediction with R stats for a type of business problem that requires a classification prediction.', 'The business question being answered is to evaluate the safety standard of cars based on certain parameters and classify them to predict Car Acceptability.', 'This data is obtained from ', 'There are many types of models that can be used for this such as Logistic Regression, Discriminant Analysis, Random Forests, and many others. You can spend a lifetime studying these.', ""We'll use an R package called Nnet to fit a single-hidden-layer neural network."", 'But before we do the modelling we need to load the data and process it to test/training sets.', ""We're predicting the "", 'Have a look at the data with the following commands', ""We'll train the model on 70% of random rows leaving the other 30% for testing."", 'The model is built.', 'The parameters used in the nnet() function can be tuned to improve performance. ', 'You can check the residuals with', ""Once you're happy with the model you can run the prediction."", 'Evaluate the prediction.', ""With Machine Learning models an important communication ability to being able to explain a model in terms of intuition. This can be tricky with Neural Networks as it's modelled after the brain !"", 'I recommend the article ', 'You can plot a Neural Network from nnet() to assist in this task. You need to install an extra function.', 'Neural Networks are a powerful unsupervised learning method to make predictions.  On this data set I found Neural Networks beat Random Forests.  You should always run different models to find the optimal results.', '© 2019 Lee Hawthorn']",post give exampl make predict r stat type busi problem requir classif predict busi question answer evalu safeti standard car base certain paramet classifi predict car accept data obtain mani type model use logist regress discrimin analysi random forest mani other spend lifetim studi use r packag call nnet fit singl hidden layer neural network model need load data process test train set predict look data follow command train model random row leav test model built paramet use nnet function tune improv perform check residu happi model run predict evalu predict machin learn model import commun abil abl explain model term intuit tricki neural network model brain recommend articl plot neural network nnet assist task need instal extra function neural network power unsupervis learn method make predict data set found neural network beat random forest alway run differ model find optim result lee hawthorn,907,-1
3,"['Power BI can use a wide variety of data sources.  This is one of the things that makes it very powerful.', 'In this post I show how you can use an R script as a data source.', 'If you have folks in your team that can program R you can take advantage of the power that R gives you i.e. run predictive analysis such as time series analysis or predict customer churn and all sorts of other analysis.  Of course, you can learn it yourself too.', 'All you need to do is provide an R data frame at the bottom of your R script.', ""Here's a simple script you can use that queries Google Trend data."", 'You can see in R Studio that ', 'When you have the script running in R Studio copy the code and open Power BI and select Get Data.  Select R Script from the Other menu.', 'You can then paste in the script.', 'At this point Power BI will run the R code and return the data.', 'I want to remove some columns so I click Edit.  Select the Date, Hits, Keyword column and then select from the menu : Remove Columns : Remove Other Columns', 'You can close and apply as per usual and create whatever visual you need.', 'You can publish the PBIX to a workspace and refresh it through a Gateway.  I tried to do this but I received a error :', 'I tried with even simpler R but this had the same error. Hopefully this bug will be sorted out.', 'Many folks are experiencing this ', "" Being able to run R scripts unlocks the power in the R ecosystem.  You're also able to process R visuals too."", ' It would be great if the R code could be run in the service so code like the example could refresh without a gateway.  I suppose this is too much to ask.  Hopefully Microsoft sort out the Bugs with the refresh.', '© 2019 Lee Hawthorn']",power bi use wide varieti data sourc one thing make power post show use r script data sourc folk team program r take advantag power r give e run predict analysi time seri analysi predict custom churn sort analysi cours learn need provid r data frame bottom r script simpl script use queri googl trend data see r studio script run r studio copi code open power bi select get data select r script menu past script point power bi run r code return data want remov column click edit select date hit keyword column select menu remov column remov column close appli per usual creat whatev visual need publish pbix workspac refresh gateway tri receiv error tri even simpler r error hope bug sort mani folk experienc abl run r script unlock power r ecosystem also abl process r visual would great r code could run servic code like exampl could refresh without gateway suppos much ask hope microsoft sort bug refresh lee hawthorn,920,1
4,"[""Cleaning data is a big part of Data Science.  Being able to script data cleaning makes it repeatable and transparent.  The best tools to do this with in my opinion are R/Python/Power Query/SQL. In this post I take some scrapped Football data and clean it up with Tidyverse packages in the R stats eco-system.  I've also created a basic Shiny app to show how this data can be further analysed."", 'The packages you need for this can be installed with tidyverse ', 'First thing to do is load the CSV data into R memory.', 'Note, this is going into a ', ""This data has many fields that I'm not going to use in this case."", 'There are around 27K rows as this data covers European football from 2005 to 2019.', ""So first step is to select the fields we're interested in."", 'We can use the Select() function to do this:', ""I don't want the Players in rows in this case, hence, a pivot is required."", 'We can use Gather() to do this:', 'This has exploded the rows to around 60K. ', ""There's a little more data cleaning.  "", 'Just a little cleaning up of the workspace left.', 'There are lots of choices to make with cleaning.  In this case I was interested in seeing Player data.  If you wanted to see Match data there would be different cleaning i.e. probably no need for the pivot.', 'With R Stats we can publish apps quite easily with Shiny.', 'I decided to try out the RpivotTable package.', ""If you're new to Shiny we need to create a Server.R and UI.R script."", ""Here's my server.R code"", 'The UI data is very simple:', 'This creates a web based Pivot table that can be used to explore data.  ', ""I've published the complete code to "", 'There are many ways to skin a cat with R.  The ', 'Shiny provides for rapid development of data applications. ', 'If you want to practice, some other actions that can be used to enhance the data :', 'The CSV is available on ', '© 2019 Lee Hawthorn']",clean data big part data scienc abl script data clean make repeat transpar best tool opinion r python power queri sql post take scrap footbal data clean tidyvers packag r stat eco system also creat basic shini app show data analys packag need instal tidyvers first thing load csv data r memori note go data mani field go use case around k row data cover european footbal first step select field interest use select function want player row case henc pivot requir use gather explod row around k littl data clean littl clean workspac left lot choic make clean case interest see player data want see match data would differ clean e probabl need pivot r stat publish app quit easili shini decid tri rpivott packag new shini need creat server r ui r script server r code ui data simpl creat web base pivot tabl use explor data publish complet code mani way skin cat r shini provid rapid develop data applic want practic action use enhanc data csv avail lee hawthorn,960,1
5,"['SQL Server Integration Services (SSIS) is a mature data integration tool bundled with SQL Server.', ""SSIS like many other tools can lead to 'dependency hell'.  This is where packages or stored procedures are developed that carry out many tasks.  With many of these packages it can be very hard for a new developer to understand the dependencies.  This makes for expensive maintenance, testing, error recovery."", 'There are frameworks around that can limit this. ', ""One of the execution frameworks I've had lots of success with is "", ""Sprockit is a powerful but lightweight ETL process controller for managing SSIS packages and T-SQL stored procedure execution. It's free, open-source and written purely in T-SQL. Richard Swinbank developed it. "", 'In this post I will show how you can create a diagram of dependencies with R stats.', 'Taking up from the end of the ', 'We first need to create a stored procedure that we can query from R.  This procedure creates Digraph text.', 'I have to give a lot of credit to Richard as he developed the initial SQL before I hacked it to work with DiagrammeR', ""I've included some format code in the code above."", 'This code is used by ', 'You can adjust this code for your own taste.', 'With this stored procedure done we can look at the R code.', ""I'm using RODBC to connect to SQL Server.  The database is on my machine and I am an admin on the database called SprocketTutorial."", 'When the data gets into R it comes with \\r\\n - these need to be removed.  ', 'Based on the tutorial on Richards site we have the following diagram :', 'You can have a look at the DiagrammeR site as there is a lot more power available for creating these graph diagrams.', 'This diagram is great for helping developers understand the dependencies that are at the heart of the Sprockit execution tool.', 'You can run this code as part of your CR pipeline to ensure your documentation is kept up to date.', '© 2019 Lee Hawthorn']",sql server integr servic ssi matur data integr tool bundl sql server ssi like mani tool lead depend hell packag store procedur develop carri mani task mani packag hard new develop understand depend make expens mainten test error recoveri framework around limit one execut framework lot success sprockit power lightweight etl process control manag ssi packag sql store procedur execut free open sourc written pure sql richard swinbank develop post show creat diagram depend r stat take end first need creat store procedur queri r procedur creat digraph text give lot credit richard develop initi sql hack work diagramm includ format code code code use adjust code tast store procedur done look r code use rodbc connect sql server databas machin admin databas call sprockettutori data get r come r n need remov base tutori richard site follow diagram look diagramm site lot power avail creat graph diagram diagram great help develop understand depend heart sprockit execut tool run code part cr pipelin ensur document kept date lee hawthorn,1038,1
6,"[""There's a new package on CRAN that makes it easier to consume Google Trend data."", 'The package to use is ', ""There are a couple of API's in this package but the interesting one is to compare the terms that are searched : "", 'You need to pass in a vector of terms (5 max).', 'You can then process it with ', ""In the code below I've added some GGMAP code to plot the interest over time. I've restricted the search to GB too but not sure how reliable this is."", 'Code to produce this chart is listed below. All packages used here are on CRAN. I used GNU R 3.6.0.', ""I'll leave it to you to draw any conclusions."", '© 2019 Lee Hawthorn']",new packag cran make easier consum googl trend data packag use coupl api packag interest one compar term search need pass vector term max process code ad ggmap code plot interest time restrict search gb sure reliabl code produc chart list packag use cran use gnu r leav draw conclus lee hawthorn,295,1
7,"['Running R on Linux is better in some cases as you have a full build environment for packages. These are compiled from C/Fortran. If you have software engineers in house this allows any mods to be made to source code if you need it.', 'I use Linux Mint 19.1 which is based on Ubuntu 18.04.', 'To install the latest version of R at the time of writing 3.6.0 I used the following steps:', 'Add a repo to my ', 'Note this is specific to the Ubuntu base packages I have. If on a different version of Ubuntu you can check the correct repo ', 'From a terminal run', 'There are some extra libraries to install for common packages hence run these commands:', 'Install ', 'Once downloaded install the package with your package manager.', 'To get started with R I recommend installing tidyverse. This is a collection of packages to make data science easier.', 'Open up R Studio and run ', 'This will take a while as a number of packages have to be downloaded and built.', 'This should get you a good clean install with a base set of packages.', '© 2019 Lee Hawthorn']",run r linux better case full build environ packag compil c fortran softwar engin hous allow mod made sourc code need use linux mint base ubuntu instal latest version r time write use follow step add repo note specif ubuntu base packag differ version ubuntu check correct repo termin run extra librari instal common packag henc run command instal download instal packag packag manag get start r recommend instal tidyvers collect packag make data scienc easier open r studio run take number packag download built get good clean instal base set packag lee hawthorn,561,-1
8,"[""Power BI is such a usable tool that I've found soon after deployment the data and calculations can grow. This isn't a bad thing as the flexibility allows users to experiment with data sources to understand value etc.."", ""The downside, if data isn't well managed it can lead to slow and unreliable models."", ""There are best practices you can follow but before diving in it's worth setting up a simple framework that includes:"", ""It's important to know about the source of data, is it a SQL Server DB? SSAS Direct Connection? Web Service, Data Warehouse?"", 'Loading data into the Power BI model is different to making a direct query. In my experience using direct query against a relational SQL source requires extensive tuning of the SQL DB. Doing this alone will require a project as SQL DB uses different technology than Power BI.', 'Also, what is the destination? Power BI Pro? Power BI Premium?', 'When are the Power BI models being used and how are they used?', ""If you have a Finance App that is being hit by the Finance department at day -3, -2, -1, 1 then it's important to know this."", ""The Board App could be used by the business leaders for their monthly management meeting. If the Finance leader is telling a story with Power BI you don't want delays as they are navigating through the model."", 'Data size and growth is important too - the model may work fine with 1 million rows but with 100 million things will be different', 'Things you can measure:', 'Focusing on the Power BI model you can focus on two areas that will impact performance in different ways.', 'Data Model', 'The Data Model is important as it determines the level of compression you get from Vertipaq as well as the model size.', ""The better the compression the less data has to be read by Vertipaq, hence, it's a big contributor to model size and speed of queries."", 'Calculated tables, columns, measures', ""For DAX calculations it's a case of identifying the most expensive calculations in use."", 'Rewriting these calculations to improve performance (too deep to go into here)', 'This is going to need advanced DAX skills as well as some understanding of the Vertipaq engine.', 'You can use a variety of tools to measure performance.', 'Optimising Power BI is not an easy task - you can only really learn by doing.  I hope at least you find a good path using the info on this post.', '© 2019 Lee Hawthorn']",power bi usabl tool found soon deploy data calcul grow bad thing flexibl allow user experi data sourc understand valu etc downsid data well manag lead slow unreli model best practic follow dive worth set simpl framework includ import know sourc data sql server db ssa direct connect web servic data warehous load data power bi model differ make direct queri experi use direct queri relat sql sourc requir extens tune sql db alon requir project sql db use differ technolog power bi also destin power bi pro power bi premium power bi model use use financ app hit financ depart day import know board app could use busi leader monthli manag meet financ leader tell stori power bi want delay navig model data size growth import model may work fine million row million thing differ thing measur focus power bi model focu two area impact perform differ way data model data model import determin level compress get vertipaq well model size better compress less data read vertipaq henc big contributor model size speed queri calcul tabl column measur dax calcul case identifi expens calcul use rewrit calcul improv perform deep go go need advanc dax skill well understand vertipaq engin use varieti tool measur perform optimis power bi easi task realli learn hope least find good path use info post lee hawthorn,1302,1
9,"['In this post I will show you how to get started with Apache Spark with Python on Windows.  This post is the first in a series of 3 that is focussed on getting Spark running.', ""In case you are wondering what Apache Spark is, I can tell you it's a unified analytics engine for large-scale data processing."", 'You can run queries using Python/Scala/Java/R/SQL against a diverse range of big data sources i.e Hadoop.  Apache Spark manages the magic to run the job on a cluster of machines to take advantage of parallel processing. ', 'Here are the steps I used to get it running on my Windows 10 laptop, note, you can follow my folder suggestions or use your own.', 'Set up user environment variables :', 'Open up a command prompt and run ', 'A python shell should open.  Check for the Spark text.', 'The Hello World for Spark is the square root test below', ""If you get the result as per below you're good to go."", 'In the next post I will show you how to install a sample database and run a real query.', '© 2019 Lee Hawthorn']",post show get start apach spark python window post first seri focuss get spark run case wonder apach spark tell unifi analyt engin larg scale data process run queri use python scala java r sql divers rang big data sourc e hadoop apach spark manag magic run job cluster machin take advantag parallel process step use get run window laptop note follow folder suggest use set user environ variabl open command prompt run python shell open check spark text hello world spark squar root test get result per good go next post show instal sampl databas run real queri lee hawthorn,573,1
10,"['When we have to deal with time sheet data it can post particular challenges for the DW if not modelled in the right way.', ""This applies to any HR/Service delivery and it's because we only tend to have Start Dates and End Dates in the source system."", 'This makes it very complex and expensive later on to calculate Count of Employees for a specific period. This is because we have to write calculations for a specific time range.', 'This presents a good example of how we can transform the model to make it less expensive for measures.', ""In this post I'll show how we can transform data with TSQL, way before it gets to the final model/mart."", ""Here's an example of some source data for an Employee table. In my experience this is very common."", 'We can transform this table by exploding out rows for each employee for the time range defined. This will make it much easier to create measures as you can simply sum a column like with a normal transaction table.', ""SQL has a join type called CROSS JOIN. It's hardly ever used. CROSS JOIN produces a result set which is the number of rows in the first table multiplied by the number of rows in the second table (with no WHERE clause). This kind of result is called a Cartesian Product."", 'In order to explode out the Employee data we need to CROSS JOIN to a Date/Time table at the grain with which we want to model with later i.e. Day.', 'You should have this Date data in a Calendar Table (very important table in the DW)', 'Step 1', 'This gives Employees * Dates which is not quite what we want as it gives us all employees for all dates.', ""We can add a where predicate to remove rows we don't want."", 'Step 2', ""We're getting there. One problem we still have is the Employee with no Termination Date i.e. the active ones will be excluded from the results."", 'Not a problem as we can run a UNION query too.', 'Step 3', ""The WHERE clause here needs to be customised for your data. In my my data NULL dates are presented as '01/01/1900'. Note also in this case I don't want to show rows for future dates. If you were going use this data for Planning then you would have to consider this."", 'The final SQL is shown below.', 'All you need now is a surrogate key. This makes the beginning of an Employee fact table.', ""Don't assume the sources tables are ready for modelling - when the end users consume your model with Self-Service tools they will have a nicer time with a fact table that has facts rather than a fact-less fact table."", '© 2019 Lee Hawthorn']",deal time sheet data post particular challeng dw model right way appli hr servic deliveri tend start date end date sourc system make complex expens later calcul count employe specif period write calcul specif time rang present good exampl transform model make less expens measur post show transform data tsql way get final model mart exampl sourc data employe tabl experi common transform tabl explod row employe time rang defin make much easier creat measur simpli sum column like normal transact tabl sql join type call cross join hardli ever use cross join produc result set number row first tabl multipli number row second tabl claus kind result call cartesian product order explod employe data need cross join date time tabl grain want model later e day date data calendar tabl import tabl dw step give employe date quit want give us employe date add predic remov row want step get one problem still employe termin date e activ one exclud result problem run union queri step claus need customis data data null date present note also case want show row futur date go use data plan would consid final sql shown need surrog key make begin employe fact tabl assum sourc tabl readi model end user consum model self servic tool nicer time fact tabl fact rather fact less fact tabl lee hawthorn,1292,1
11,"['When data is stored in OLAP cubes on SQL Server this can be a convenient data source for analysts as the data is pre-cleaned and the model is usually named with known business entities like Product, Division, Customer etc...', ""OLAP cubes should be optimised to return query results within a few seconds. Compare this to a SQL query that can take hours. This helps the analyst with data exploration. I wouldn't recommend using SSAS cubes for training data but you can at least follow the data lineage from the cube to locate the relevant source data."", 'You can query SSAS cubes with a version of R that comes from Microsoft.', ""The package needed is olapR - note, I can't find this in the CRAN repository, hence, you have to use the R version provided by "", ""It would be easier if Microsoft published the package to CRAN but you can't have everything. When I first learnt R in 2015 there was no OLAP package in CRAN and I had to use manual hacks to get OLAP data into R."", ""If you're using the GNU R with R Studio you can change your version of R temporarily :"", ""Once you've restarted R you can install the package"", ""Note, the Microsoft docs need updating for SQL Server 2017 Tabular Cubes with a compatibility of 1400 (I've submitted feedback to them via GitHub docs)"", 'Assuming you have a SSAS tabular cube deployed and processed here is what you need (when SSAS is on same machine).', 'Note, with 1400 cubes you need to include the cube name in the connection string under [Initial Catalog]', 'In the code below you need to name the cube ""Model"" as this is the alias that is used. This is different to 1200 compatibility (SQL Server 2016) where you need to replace Model with the name of your cube.', ""It's best if you craft the MDX as this will give you the ultimate power that MDX provides. OlapR comes with an "", ""If using a tabular model you can write DAX :-) I can't see this documented on the Microsoft site but it seems to work."", 'This code loads the results of the MDX/DAX query into a Dataframe.', ""You'll notice there is a bit of cleaning up of column names required."", 'Many organisations have cubes already deployed, hence, they provide a great source for data exploration to give the analyst/data scientist a head start. Leverage the data assets already in place.', '© 2019 Lee Hawthorn']",data store olap cube sql server conveni data sourc analyst data pre clean model usual name known busi entiti like product divis custom etc olap cube optimis return queri result within second compar sql queri take hour help analyst data explor recommend use ssa cube train data least follow data lineag cube locat relev sourc data queri ssa cube version r come microsoft packag need olapr note find cran repositori henc use r version provid would easier microsoft publish packag cran everyth first learnt r olap packag cran use manual hack get olap data r use gnu r r studio chang version r temporarili restart r instal packag note microsoft doc need updat sql server tabular cube compat submit feedback via github doc assum ssa tabular cube deploy process need ssa machin note cube need includ cube name connect string initi catalog code need name cube model alia use differ compat sql server need replac model name cube best craft mdx give ultim power mdx provid olapr come use tabular model write dax see document microsoft site seem work code load result mdx dax queri datafram notic bit clean column name requir mani organis cube alreadi deploy henc provid great sourc data explor give analyst data scientist head start leverag data asset alreadi place lee hawthorn,1269,1
12,"['Living in the city of Chester I sometimes think the old Deva Victrix (79AD) city is still in the air.', 'We have a 6 story luxury student block being planned for development at the end of my road.  When deciding to support / object to this development I wanted to know if this was based on real need.', 'Chester already has lots of student housing, both multiple occupancy homes and newer student blocks.  The latter being more expensive.', 'Like other university cities Chester has a superb community of students that bring energy and life to the city.  The University of Chester is an important asset to the city that helps power growth.', 'Student blocks are being developed by third-parties and sold to investors looking for returns at the expense of students/taxpayers.  I wanted to know if the development was speculative or for a real need.', 'After reaching out to my local authority I was shocked to discover there was no open data available on this controversial subject.  ', 'We live in a data rich society.  It’s way past time we had this data in my opinion.  To answer my question  I really needed some level of ‘occupancy’ data.', ""It didn't take me long to find "", 'This data was stuck on a poorly formatted web site.   Available to all but not exactly formatted for easy access.  No API.  Can’t really blame the 3rd party running the website, they are doing the important job of matching students with housing after all.  Not sure what happened to the semantic web.', 'With Python on my Pi I wanted to see if it was possible to automate the scraping, processing, presentation.   A micro-BI project carried out over a a couple of Sunday mornings.', 'One of the popular Python packages for scraping data is ', 'It’s great to see SQL Server come to Linux.   Would have liked to have used it but I needed something much lighter for my Pi.   I was keen to store this data with schema rather than dump it into JSON.\nSqLite is so popular but I’ve never had a use for it.  It’s on most of our phones as mobile phone developers use it for local data persistence.  Thought I’d give it a try.  Can’t be hard, SQL is a standard after all.', 'I would of loved to have used Power BI.  I didn’t bother looking for a Pi data gateway for SqLite on Linux.', 'On R we have excellent visualisation libraries such as GGPlot.  Wondered what was available on Python.  ', 'The code is available ', 'Incidentally, I did this development on my Windows machine using VS Code with Python Tools installed, it provides a very refreshing debugging/linting experience.  ', 'My only gripe was that I’d like to be able to see Pandas Data Frames more easily when debugging.  Seeing the stack is fun but too deep in many cases.  I suppose I’m spoilt by RStudio.', 'I was surprised that I didn’t need to modify the code (other than changing the working path) to get it running on the Pi.  This applied to the full stack.  Oh how times are changing.', 'The web data does indeed show there are empty properties spread across Chester.\nThis data should be available for society.  We shouldn’t need hacking skills to get the data in my opinion.', 'After I joined the local community action group I found that local authorities across the country have very disparate data services.  It seems the improvements we’ve seen from the Gov haven’t filtered down to our cash strapped Local Authorities yet.', '© 2019 Lee Hawthorn']",live citi chester sometim think old deva victrix ad citi still air stori luxuri student block plan develop end road decid support object develop want know base real need chester alreadi lot student hous multipl occup home newer student block latter expens like univers citi chester superb commun student bring energi life citi univers chester import asset citi help power growth student block develop third parti sold investor look return expens student taxpay want know develop specul real need reach local author shock discov open data avail controversi subject live data rich societi way past time data opinion answer question realli need level occup data take long find data stuck poorli format web site avail exactli format easi access api realli blame rd parti run websit import job match student hous sure happen semant web python pi want see possibl autom scrape process present micro bi project carri coupl sunday morn one popular python packag scrape data great see sql server come linux would like use need someth much lighter pi keen store data schema rather dump json nsqlite popular never use phone mobil phone develop use local data persist thought give tri hard sql standard would love use power bi bother look pi data gateway sqlite linux r excel visualis librari ggplot wonder avail python code avail incident develop window machin use vs code python tool instal provid refresh debug lint experi gripe like abl see panda data frame easili debug see stack fun deep mani case suppos spoilt rstudio surpris need modifi code chang work path get run pi appli full stack oh time chang web data inde show empti properti spread across chester nthi data avail societi need hack skill get data opinion join local commun action group found local author across countri dispar data servic seem improv seen gov filter cash strap local author yet lee hawthorn,1862,1
13,"[""BI projects have complex elements such as dimensional modelling, modelling facts, hierarchies, calculations etc..\nThis makes it essential that Business Analysis is applied\xa0on all projects. \xa0It's during the BA phase that requirements are picked up. \xa0"", ""As a BI professional it's important you use your judgement to tease out requirements that users may not be aware of, for instance, slowly changing dimensions, late arriving facts, late arriving dimensions."", 'You can also start to detect data quality, although, data profiling is the key tool to determine data quality. \xa0Users will often give their opinion on data quality.', 'You can also get an understanding of the largest tables and any fact grained dimensions.\nFor some BI projects there are limited facts, we see this with HR & Legal. \xa0', ""It's very important to determine this early on. \xa0This doesn't prevent users from requesting facts, for instance, a hiring manager may wish to see the number of new hires or the number of applicants. \xa0If this fact isn't available it's going to have to be created or inferred based on some other field such as Hire Date."", ""It's also important you understand the process that underlies the OLTP database. \xa0 With BA tools you can document this process. \xa0 I had one situation where a billing process included dynamic revenue types. \xa0 The user wanted to analyse and report on revenue. \xa0 This required master data to be added to the ETL pipeline. \xa0Not a small feat. It's things like this you want to know about early on."", ""There's a lot more that I won't go into...currency translation, cost allocations, complex measures."", ""It's vitally important these things are well understood before development starts."", '© 2019 Lee Hawthorn']",bi project complex element dimension model model fact hierarchi calcul etc nthi make essenti busi analysi appli xa project xa ba phase requir pick xa bi profession import use judgement teas requir user may awar instanc slowli chang dimens late arriv fact late arriv dimens also start detect data qualiti although data profil key tool determin data qualiti xa user often give opinion data qualiti also get understand largest tabl fact grain dimens nfor bi project limit fact see hr legal xa import determin earli xa prevent user request fact instanc hire manag may wish see number new hire number applic xa fact avail go creat infer base field hire date also import understand process underli oltp databas xa ba tool document process xa one situat bill process includ dynam revenu type xa user want analys report revenu xa requir master data ad etl pipelin xa small feat thing like want know earli lot go currenc translat cost alloc complex measur vital import thing well understood develop start lee hawthorn,1008,-1
14,"['When holding a workshop to collect requirements for a BI project you can take two broad approaches.', ""Don't assume users know what they want. \xa0 Adapt your action to the situation at hand."", '© 2019 Lee Hawthorn']",hold workshop collect requir bi project take two broad approach assum user know want xa adapt action situat hand lee hawthorn,125,1
15,"['This post is about calling R functions from Power BI. The use case for this is utilising the functions created by Data Scientists i.e. scoring alogrithms, predictions on churn, risk assessment models and more.', ""I know from previous experience that Power BI can query REST API's so I decided to give it try."", 'First thing is to prefix R functions with attributes as per the R Plumber docs.', 'To keep this simple I used the sample code in the R Plumber docs.', 'To serve up these functions you can use this code to launch the server on port 8000 on localhost.', 'I was primarily interested in calling the /sum function. This requires a POST request though so we need to get our hands dirty with M.', 'I remember creating a POST request several years ago when Power Query was called Data Explorer. Would the same technique work I wondered.', 'The first thing I wanted to do was test the end point. If on Linux/Mac you can use Curl to do this.', 'I ended up using Postman on Windows.', 'Notice the request is POST and we need to specify parameters as per the function signature. I see the results being returned, great, plumbing done.', 'To call this function from Power BI you need to write M code as the standard Web source only makes a GET request.', 'This data comes into Power Query initially as JSON and ended up in a LIST. A few extra steps are needed to turn this into a TABLE and change the data type from text whole number.', 'The key M code is listed below. Note the addition of the Content parmeter. When you use the Content parameter the web request changes from GET to POST. The text parameters also need to be encoded in Binary, hence Text.ToBinary()', 'The complete M code is listed below', ""Of course in the real world you will need to authenticate to a deployed web service. If I had more time I would love to see how far this goes i.e published to the Power BI service and with a data frame rather than single value, it should work in theory but I've not tested this."", 'You have multiple options to deploy R code depending on the infrastructure and tools you have. You now have an open source method of deploying R functions.', '© 2019 Lee Hawthorn']",post call r function power bi use case utilis function creat data scientist e score alogrithm predict churn risk assess model know previou experi power bi queri rest api decid give tri first thing prefix r function attribut per r plumber doc keep simpl use sampl code r plumber doc serv function use code launch server port localhost primarili interest call sum function requir post request though need get hand dirti rememb creat post request sever year ago power queri call data explor would techniqu work wonder first thing want test end point linux mac use curl end use postman window notic request post need specifi paramet per function signatur see result return great plumb done call function power bi need write code standard web sourc make get request data come power queri initi json end list extra step need turn tabl chang data type text whole number key code list note addit content parmet use content paramet web request chang get post text paramet also need encod binari henc text tobinari complet code list cours real world need authent deploy web servic time would love see far goe e publish power bi servic data frame rather singl valu work theori test multipl option deploy r code depend infrastructur tool open sourc method deploy r function lee hawthorn,1274,1
16,"['When creating BI models and looking into the guts of the ERP system you see data artifacts from user behavior or sometimes poor design which requires you to get out cleaning gear.', 'It goes without saying the best course of action is to clean data at source – if only this could happen more often.', 'In this post I’ll show a little example I learnt recently to infer dates with T-SQL.', 'In the scenario below we have HR data showing employees at various positions over time.\nThe time frame of each position is represented with Valid From and Valid To dates.', 'The integrity of this data is crucial if the fields are going to be used in a join.', 'When the validTo date is flaky we can infer the date by looking at the validFrom\nof the employees next position. Usually this requires a complex query with self-joins and other manners of madness.', 'T-SQL in SQL Server 2012+ gives us the LEAD function. We can use LEAD() to write a simple query with fewer lines of code. It works by partitioning the data into sets split by employee. Each set is sorted by validFrom so the next row gives us the date needed. I had to use DATEADD to subtract 1 from the next ValidTo date was there was an issue using LEAD with int and dates.', 'You can set up the data with the code below. I’ve added real ValidTo dates to show the inference is correct.', '© 2019 Lee Hawthorn']",creat bi model look gut erp system see data artifact user behavior sometim poor design requir get clean gear goe without say best cours action clean data sourc could happen often post show littl exampl learnt recent infer date sql scenario hr data show employe variou posit time nthe time frame posit repres valid valid date integr data crucial field go use join validto date flaki infer date look validfrom nof employe next posit usual requir complex queri self join manner mad sql sql server give us lead function use lead write simpl queri fewer line code work partit data set split employe set sort validfrom next row give us date need use dateadd subtract next validto date issu use lead int date set data code ad real validto date show infer correct lee hawthorn,768,1
17,"['When we’re carrying out analysis once we’ve got clean transformed data we have to create a model.', 'There are many types of models that can be used depending on the type of analysis or prediction being made. For instance, predicting a class, predicting values, finding unusual points.', 'Within each collection of models I’d really like to be able to spin through the models and selectively apply each to my dataset. I want to see the Accuracy, p-Value, Sensitivity, Specificity etc.. ranked.', 'With the model algorithms already pre-baked why can’t we just consume them in a fairly efficient way?', 'Of course we can do this by hand with Python or R but it would be much better if the software handled this type of plumbing/set-up.', 'Here’s an ', '© 2019 Lee Hawthorn']",carri analysi got clean transform data creat model mani type model use depend type analysi predict made instanc predict class predict valu find unusu point within collect model realli like abl spin model select appli dataset want see accuraci p valu sensit specif etc rank model algorithm alreadi pre bake consum fairli effici way cours hand python r would much better softwar handl type plumb set lee hawthorn,410,1
18,"['Web Scraping is used to pull data from web pages when an API is unavailable.  Imagine copying the data by hand (horrible chore) this is essentially web scraping.', 'I’ve wanted to get my head around this for a while and see if modern sites are structured in ways to make this easier.', 'When I was researching wine types for another project an opportunity came up.', 'The packages we can use to make our life easier are:', 'There’s one other tool that’s recommended, ', 'The first thing to do when scraping a page is to browse to the page.', 'We can then use the Selectorgadget tool to detect the right CSS selector. In the screenshot below I’ve clicked over the abstract and the class .productAbstract has been selected.  We know it’s the right selector as the other items in the list are highlighted.  A little patience is required here as there can be different selectors in the CSS which can give erroneous data.', 'The other selector we need is .productList.', 'With this information we’re good to go.', 'The script starts with loading the libraries and setting the URL we found earlier. I’ve increased the pagelength for illustration purposes.', 'To pull the web page into R’s memory we simply use ', 'We can then use the selector we found earlier to extract the data.', 'We can do a similar thing to extract the Abstract.', 'That is not helpful at all.  We have \\r\\n and too much space.  Fear not, we can use stringi to clean up the data.   When I look at a problem like this I breakdown the problem into smaller bits and solve these individually.  So in this spirit we’ll handle the \\r\\n problem first.', 'This is simply replacing the string “\\r\\n” with empty.  Of course with Regex there are many ways to skin a cat.   If you want to learn more feel free.', 'We have spaces left to eliminate.  Notice I’m searching for double space as I don’t want to remove the space from the abstract itself.', 'We add the product and abstract columns together, add columns names and export to CSV.  Job done.', 'The complete code is listed below', '© 2019 Lee Hawthorn']",web scrape use pull data web page api unavail imagin copi data hand horribl chore essenti web scrape want get head around see modern site structur way make easier research wine type anoth project opportun came packag use make life easier one tool recommend first thing scrape page brows page use selectorgadget tool detect right css selector screenshot click abstract class productabstract select know right selector item list highlight littl patienc requir differ selector css give erron data selector need productlist inform good go script start load librari set url found earlier increas pagelength illustr purpos pull web page r memori simpli use use selector found earlier extract data similar thing extract abstract help r n much space fear use stringi clean data look problem like breakdown problem smaller bit solv individu spirit handl r n problem first simpli replac string r n empti cours regex mani way skin cat want learn feel free space left elimin notic search doubl space want remov space abstract add product abstract column togeth add column name export csv job done complet code list lee hawthorn,1115,1
19,"['As an Excel power user I know Excel can be used to do pretty much anything – I’ve even seen Excel being used to play the Game of Life.   If this is the case why do we need R?', 'In this post I’ll tell you why and then show you.', 'We can write an R script once to do any of the  following :', 'If the R is written in the correct way it’s reproducible by default.  This is very beneficial if data is dynamic or if you need to pass the script to a colleague.  You don’t want them getting a different result.', 'Excel is flexible as mentioned above.  Excel is also limited by the resources Microsoft decide to invest in the product.  Even if Microsoft had the resources I think they would only include functionality that is useful for a broad spectrum of people.', ""How about R?   First off, it’s open source which means if  we need a real niche feature we can write it ourselves and many people do. Furthermore, the architecture of R is based around a package system which makes it highly adaptable.   To be fair, Excel has extensibility (VBA, COM, .NET) but to write an extension one has to learn a different language.   Packages in R are written with R and C if it's needed.  There’s a little extra to learn but learn to use R and you’re very close to being a package author."", 'At the time of writing there are over 6000 packages available for use.  Given R’s long lineage I am willing to bet that the problem you have will have been solved by someone else.', 'You can run R in lots of different places:', 'It’s important to know that R runs in-memory. This makes it very fast, although memory can be a constraint.', 'With R we can send the output to lots of different places.  We’re not constrained by a worksheet.', 'Okay, enough theory.  Here’s an example of customer analysis.   The problem we’re seeing is that customers are disappearing.  We need to find more insight before we can look to mitigate the problem.', 'As you can see in the Excel screenshot below, I’ve pulled in data from a database and grouped customers based on demographics. We see 12 months of customer count.', 'The second table is a copy of the first but with customer count aligned to the left (for charting/formula clarity).   I did this by hand. You could it with a formula to be fair.  The next table calculates Retention which takes the current month count and divides by month 1.   With this third table it’s simple to create a chart.', 'We’ve solved our problem.  What is going on with group 4?', 'It’s not all good though.  What happens if we see more groups in the database?  Or more months?  This worksheet doesn’t grow.   I know we can structure the workbook to make it expandable.  We can use dynamic ranges to populate the chart.   This is okay for me.  I’m a power user after all.  What about the other users?  Wouldn’t it be good if we could forget about structure and layout and just focus on the problem at hand?', 'This is what R gives us. I wrote the code and published to a website using R Markdown.  R Markdown gives us a facility to write a report or slides and embed R directly in the document.  You can find a copy of the R Markdown ', '© 2019 Lee Hawthorn']",excel power user know excel use pretti much anyth even seen excel use play game life case need r post tell show write r script follow r written correct way reproduc default benefici data dynam need pass script colleagu want get differ result excel flexibl mention excel also limit resourc microsoft decid invest product even microsoft resourc think would includ function use broad spectrum peopl r first open sourc mean need real nich featur write mani peopl furthermor architectur r base around packag system make highli adapt fair excel extens vba com net write extens one learn differ languag packag r written r c need littl extra learn learn use r close packag author time write packag avail use given r long lineag will bet problem solv someon els run r lot differ place import know r run memori make fast although memori constraint r send output lot differ place constrain worksheet okay enough theori exampl custom analysi problem see custom disappear need find insight look mitig problem see excel screenshot pull data databas group custom base demograph see month custom count second tabl copi first custom count align left chart formula clariti hand could formula fair next tabl calcul retent take current month count divid month third tabl simpl creat chart solv problem go group good though happen see group databas month worksheet grow know structur workbook make expand use dynam rang popul chart okay power user user good could forget structur layout focu problem hand r give us wrote code publish websit use r markdown r markdown give us facil write report slide emb r directli document find copi r markdown lee hawthorn,1636,1
20,"['Time Series analysis is a fundamental aspect of performance management.   Before we can begin to model time-series there’s huge dividend in just visualising the data.  We can see if there is a seasonal pattern, or is the time-series additive or multiplicative.', 'R comes with good plotting but one thing I’ve always wanted to do is zoom around a time-series. This is because patterns at the lower level are not always visible. We often have to group time to see the pattern but this is a transform I could do without.', 'At the last R London meetup I saw an excellent presentation from Enzo Martoglio who demonstrated HTML Widgets.  HTML widgets for R provide a bridge between R and HTML/JavaScript visualization libraries.', 'This opens a door for analysts and enables modern tools to be used for communicating model output.  I’ll leave that for another post. Back to time-series.', 'I kid you not, with 3 lines of code I was able to create an interactive time-series chart with zoom.  The package to use is dygraphs.   Basic example below.', 'We can see the seasonal pattern and the multiplicative trend.  This means a log transform will be needed before an additive model can be used. I’ll be posting more about time-series in the coming months.', 'These widgets can be output to the usual places:', 'There are so many use cases for this.  It’s going to be interesting to see where things go.', '© 2019 Lee Hawthorn']",time seri analysi fundament aspect perform manag begin model time seri huge dividend visualis data see season pattern time seri addit multipl r come good plot one thing alway want zoom around time seri pattern lower level alway visibl often group time see pattern transform could without last r london meetup saw excel present enzo martoglio demonstr html widget html widget r provid bridg r html javascript visual librari open door analyst enabl modern tool use commun model output leav anoth post back time seri kid line code abl creat interact time seri chart zoom packag use dygraph basic exampl see season pattern multipl trend mean log transform need addit model use post time seri come month widget output usual place mani use case go interest see thing go lee hawthorn,776,1
21,"['Here’s an example of using web services to source data & processing from 3rd parties.  I queried Yelp for top venues, used Google Maps to retrieve a distance matrix.  I then used an R package TSP to calculate the optimal route.  Finally plotting the route on Google Maps.', 'I presented this at ManchesterR in Feb-15. Slides are available ', 'Code walk-through can be found on ', '© 2019 Lee Hawthorn']",exampl use web servic sourc data process rd parti queri yelp top venu use googl map retriev distanc matrix use r packag tsp calcul optim rout final plot rout googl map present manchesterr feb slide avail code walk found lee hawthorn,232,1
